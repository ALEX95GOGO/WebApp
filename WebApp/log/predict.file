
Please cite the following paper when using nnUNet:
Fabian Isensee, Paul F. JÃ¤ger, Simon A. A. Kohl, Jens Petersen, Klaus H. Maier-Hein "Automated Design of Deep Learning Methods for Biomedical Image Segmentation" arXiv preprint arXiv:1904.08128 (2020).
If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

using model stored in  /home/data/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task155_LungL/nnUNetTrainerV2_noDeepSupervision__nnUNetPlansv2.1
This model expects 1 input modalities for each image
Found 19 unique case ids, here are some examples: ['LungL_006523' 'LungL_006805' 'LungL_006542' 'LungL_007580'
 'LungL_003718' 'LungL_006972' 'LungL_006582' 'LungL_007688'
 'LungL_006471' 'LungL_007580']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
number of cases: 19
number of cases that still need to be predicted: 0
emptying cuda cache
loading parameters for folds, [0]
2021-04-29 03:19:06.787712: Using dummy2d data augmentation
using the following model files:  ['/home/data/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task155_LungL/nnUNetTrainerV2_noDeepSupervision__nnUNetPlansv2.1/fold_0/model_best.model']
starting preprocessing generator
starting prediction...
inference done. Now waiting for the segmentation export to finish...
WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!
The folder you need to run this in is /home/data/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task155_LungL/nnUNetTrainerV2_noDeepSupervision__nnUNetPlansv2.1
